{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarijaGijic/Julia_kernel_abstractions/blob/main/2D_dilation_erosion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ1r1bbb0yBv"
      },
      "source": [
        "# <img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"100\" /> _Colab Notebook Template_\n",
        "\n",
        "## Instructions\n",
        "1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n",
        "2. If you need a GPU: _Runtime_ > _Change runtime type_ > _Harware accelerator_ = _GPU_.\n",
        "3. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia and other packages (if needed, update `JULIA_VERSION` and the other parameters). This takes a couple of minutes.\n",
        "4. Reload this page (press Ctrl+R, or ⌘+R, or the F5 key) and continue to the next section.\n",
        "\n",
        "_Notes_:\n",
        "* If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2, 3 and 4.\n",
        "* After installation, if you want to change the Julia version or activate/deactivate the GPU, you will need to reset the Runtime: _Runtime_ > _Factory reset runtime_ and repeat steps 3 and 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIeFXS0F0zww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "f18ebf8a-8a2e-42a6-e0aa-ff6aa09563f3"
      },
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.8.2\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  nvidia-smi -L &> /dev/null && export GPU=1 || export GPU=0\n",
        "  if [ $GPU -eq 1 ]; then\n",
        "    JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia\n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Unrecognized magic \u001b[36m%%shell\u001b[39m.\n",
              "\n",
              "  Julia does not use the IPython \u001b[36m%magic\u001b[39m syntax. To interact with the IJulia kernel, use\n",
              "  \u001b[36mIJulia.somefunction(...)\u001b[39m, for example. Julia macros, string macros, and functions can be used to\n",
              "  accomplish most of the other functionalities of IPython magics."
            ],
            "text/markdown": "Unrecognized magic `%%shell`.\n\nJulia does not use the IPython `%magic` syntax.   To interact with the IJulia kernel, use `IJulia.somefunction(...)`, for example.  Julia macros, string macros, and functions can be used to accomplish most of the other functionalities of IPython magics.\n",
            "text/latex": "Unrecognized magic \\texttt{\\%\\%shell}.\n\nJulia does not use the IPython \\texttt{\\%magic} syntax.   To interact with the IJulia kernel, use \\texttt{IJulia.somefunction(...)}, for example.  Julia macros, string macros, and functions can be used to accomplish most of the other functionalities of IPython magics.\n\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OS3Ac017T1i"
      },
      "source": [
        "# Checking the Installation\n",
        "The `versioninfo()` function should print your Julia version and some other info about the system:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEzvvzCl1i0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50259130-92ca-47f1-d94c-2da3891f32fe"
      },
      "source": [
        "versioninfo()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Julia Version 1.10.9\n",
            "Commit 5595d20a287 (2025-03-10 12:51 UTC)\n",
            "Build Info:\n",
            "  Official https://julialang.org/ release\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-linux-gnu)\n",
            "  CPU: 2 × Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-15.0.7 (ORCJIT, skylake-avx512)\n",
            "Threads: 2 default, 0 interactive, 1 GC (on 2 virtual cores)\n",
            "Environment:\n",
            "  LD_LIBRARY_PATH = /usr/lib64-nvidia\n",
            "  JULIA_NUM_THREADS = auto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using Pkg\n",
        "Pkg.add(\"BenchmarkTools\")\n",
        "using BenchmarkTools\n",
        "\n",
        "M = rand(2^11, 2^11)\n",
        "\n",
        "@btime $M * $M;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjM_qq54lCcs",
        "outputId": "75f36c20-0717-4ae5-bbcd-0630e860ce98"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BenchmarkTools ─ v1.6.0\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.10/Project.toml`\n",
            "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.6.0\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.10/Manifest.toml`\n",
            "  \u001b[90m[6e4b80f9] \u001b[39m\u001b[92m+ BenchmarkTools v1.6.0\u001b[39m\n",
            "  \u001b[90m[9abbd945] \u001b[39m\u001b[92m+ Profile\u001b[39m\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m packages...\n",
            "   2695.6 ms\u001b[32m  ✓ \u001b[39mBenchmarkTools\n",
            "  1 dependency successfully precompiled in 12 seconds. 460 already precompiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  256.226 ms (2 allocations: 32.00 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XciCcMAJOT3_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4613bf30-b465-4d4f-b4e7-cbdf388479aa"
      },
      "source": [
        "try\n",
        "    using CUDA\n",
        "catch\n",
        "    println(\"No GPU found.\")\n",
        "else\n",
        "    run(`nvidia-smi`)\n",
        "    # Create a new random matrix directly on the GPU:\n",
        "    M_on_gpu = CUDA.CURAND.rand(2^11, 2^11)\n",
        "    @btime $M_on_gpu * $M_on_gpu; nothing\n",
        "end"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr  8 19:14:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "  254.606 ms (2 allocations: 32.00 MiB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RC1QNNqk6h1"
      },
      "source": [
        "# Need Help?\n",
        "\n",
        "* Learning: https://julialang.org/learning/\n",
        "* Documentation: https://docs.julialang.org/\n",
        "* Questions & Discussions:\n",
        "  * https://discourse.julialang.org/\n",
        "  * http://julialang.slack.com/\n",
        "  * https://stackoverflow.com/questions/tagged/julia\n",
        "\n",
        "If you ever ask for help or file an issue about Julia, you should generally provide the output of `versioninfo()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UMidUQB03vJ"
      },
      "source": [
        "Add new code cells by clicking the `+ Code` button (or _Insert_ > _Code cell_).\n",
        "\n",
        "Have fun!\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/JuliaLang/julia-logo-graphics/master/images/julia-logo-mask.png\" height=\"100\" />"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using Pkg\n",
        "Pkg.add(\"CUDA\")\n",
        "Pkg.add(\"AMDGPU\")\n",
        "Pkg.add(\"KernelAbstractions\")"
      ],
      "metadata": {
        "id": "L1Dg0HKV0QQb",
        "outputId": "fadfbd5b-88b9-4d5b-81a0-3f1f69eada52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Project.toml`\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Manifest.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m InitialValues ────── v0.3.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BangBang ─────────── v0.4.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CompositionsBase ─── v0.1.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ROCmDeviceLibs_jll ─ v5.6.1+1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LLVM_jll ─────────── v15.0.7+10\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StableTasks ──────── v0.1.7\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Accessors ────────── v0.1.42\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OhMyThreads ──────── v0.8.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChunkSplitters ───── v3.1.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m TaskLocalValues ──── v0.1.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m AMDGPU ───────────── v1.2.7\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m AcceleratedKernels ─ v0.3.3\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.10/Project.toml`\n",
            "  \u001b[90m[21141c5a] \u001b[39m\u001b[92m+ AMDGPU v1.2.7\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.10/Manifest.toml`\n",
            "  \u001b[90m[21141c5a] \u001b[39m\u001b[92m+ AMDGPU v1.2.7\u001b[39m\n",
            "  \u001b[90m[6a4ca0a5] \u001b[39m\u001b[92m+ AcceleratedKernels v0.3.3\u001b[39m\n",
            "  \u001b[90m[7d9f7c33] \u001b[39m\u001b[92m+ Accessors v0.1.42\u001b[39m\n",
            "  \u001b[90m[198e06fe] \u001b[39m\u001b[92m+ BangBang v0.4.4\u001b[39m\n",
            "  \u001b[90m[ae650224] \u001b[39m\u001b[92m+ ChunkSplitters v3.1.2\u001b[39m\n",
            "  \u001b[90m[a33af91c] \u001b[39m\u001b[92m+ CompositionsBase v0.1.2\u001b[39m\n",
            "  \u001b[90m[22cec73e] \u001b[39m\u001b[92m+ InitialValues v0.3.1\u001b[39m\n",
            "  \u001b[90m[67456a42] \u001b[39m\u001b[92m+ OhMyThreads v0.8.2\u001b[39m\n",
            "  \u001b[90m[91464d47] \u001b[39m\u001b[92m+ StableTasks v0.1.7\u001b[39m\n",
            "  \u001b[90m[ed4db957] \u001b[39m\u001b[92m+ TaskLocalValues v0.1.2\u001b[39m\n",
            "\u001b[33m⌅\u001b[39m \u001b[90m[86de99a1] \u001b[39m\u001b[92m+ LLVM_jll v15.0.7+10\u001b[39m\n",
            "  \u001b[90m[873c0968] \u001b[39m\u001b[92m+ ROCmDeviceLibs_jll v5.6.1+1\u001b[39m\n",
            "  \u001b[90m[d55e3150] \u001b[39m\u001b[92m+ LLD_jll v15.0.7+10\u001b[39m\n",
            "  \u001b[90m[8f36deef] \u001b[39m\u001b[92m+ libLLVM_jll v15.0.7+10\u001b[39m\n",
            "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m packages...\n",
            "   1074.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mTaskLocalValues\u001b[39m\n",
            "   1106.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCompositionsBase\u001b[39m\n",
            "   2002.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mInitialValues\u001b[39m\n",
            "    887.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mChunkSplitters\u001b[39m\n",
            "   1043.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStableTasks\u001b[39m\n",
            "    769.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLLD_jll\u001b[39m\n",
            "    946.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mROCmDeviceLibs_jll\u001b[39m\n",
            "    677.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCompositionsBase → CompositionsBaseInverseFunctionsExt\u001b[39m\n",
            "   1227.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLLVM_jll\u001b[39m\n",
            "   2254.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors\u001b[39m\n",
            "    594.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → LinearAlgebraExt\u001b[39m\n",
            "   1803.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → StructArraysExt\u001b[39m\n",
            "   1868.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → IntervalSetsExt\u001b[39m\n",
            "   1980.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → TestExt\u001b[39m\n",
            "   1659.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → UnitfulExt\u001b[39m\n",
            "   1577.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang\u001b[39m\n",
            "   1827.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → StaticArraysExt\u001b[39m\n",
            "   1191.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangChainRulesCoreExt\u001b[39m\n",
            "   1388.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangTablesExt\u001b[39m\n",
            "   1685.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOhMyThreads\u001b[39m\n",
            "   1170.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOhMyThreads → MarkdownExt\u001b[39m\n",
            "   1683.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangStaticArraysExt\u001b[39m\n",
            "   3112.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangDataFramesExt\u001b[39m\n",
            "   3801.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAcceleratedKernels\u001b[39m\n",
            "  14096.7 ms\u001b[32m  ✓ \u001b[39mAMDGPU\n",
            "   5794.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLDataDevices → MLDataDevicesAMDGPUExt\u001b[39m\n",
            "   5982.3 ms\u001b[32m  ✓ \u001b[39mAMDGPU → AMDGPUEnzymeCoreExt\n",
            "   6021.9 ms\u001b[32m  ✓ \u001b[39mAMDGPU → AMDGPUChainRulesCoreExt\n",
            "   2562.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNNlib → NNlibAMDGPUExt\u001b[39m\n",
            "  29 dependencies successfully precompiled in 40 seconds. 462 already precompiled.\n",
            "  \u001b[33m1\u001b[39m dependency had output during precompilation:\u001b[33m\n",
            "┌ \u001b[39mNNlib → NNlibAMDGPUExt\u001b[33m\n",
            "│  \u001b[39m\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mROCm MIOpen is not available for AMDGPU.\u001b[33m\n",
            "│  \u001b[39m\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mNNlib has limited functionality for AMDGPU.\u001b[33m\n",
            "│  \u001b[39m\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ NNlibAMDGPUExt ~/.julia/packages/NNlib/CGMj3/ext/NNlibAMDGPUExt/NNlibAMDGPUExt.jl:58\u001b[39m\u001b[33m\n",
            "└  \u001b[39m\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.10/Project.toml`\n",
            "  \u001b[90m[63c18a36] \u001b[39m\u001b[92m+ KernelAbstractions v0.9.34\u001b[39m\n",
            "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.10/Manifest.toml`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "abstract type AbstractImageNew end;\n",
        "\n",
        "struct Image2D_{T} <: AbstractImageNew\n",
        "    height_::T\n",
        "    width_::T\n",
        "\n",
        "end\n",
        "\n",
        "struct Image3D_{T} <: AbstractImageNew\n",
        "    height_::T\n",
        "    width_::T\n",
        "    depth_::T\n",
        "\n",
        "end\n",
        "\n",
        "function create_rand_image_2D(image::Image2D_{Int64})\n",
        "    h = image.height_\n",
        "    w = image.width_\n",
        "    return rand(Bool, h, w)\n",
        "\n",
        "end\n",
        "\n",
        "function create_rand_image_3D(image::Image3D_{Int64})\n",
        "    h = image.height_\n",
        "    w = image.width_\n",
        "    d = image.depth_\n",
        "    return rand(Bool, h, w, d)\n",
        "end"
      ],
      "metadata": {
        "id": "GjRpYMJl3cx6",
        "outputId": "ee8408d7-bd65-4b9b-be32-d3cab9dc4176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "create_rand_image_3D (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using KernelAbstractions, Test\n",
        "\n",
        "#------------------------------------dilation---------------------------------------\n",
        "\n",
        "@kernel function dilate_kernel!(output_img, input_img, struct_element)\n",
        "    I = @index(Global, Cartesian)\n",
        "    i, j = Tuple(I)\n",
        "    offset_h = div(size(struct_element)[1], 2)\n",
        "    offset_w = div(size(struct_element)[2], 2)\n",
        "\n",
        "    if i <= size(input_img, 1) && j <= size(input_img, 2)\n",
        "        result = false\n",
        "\n",
        "        for m in 1:size(struct_element)[1]\n",
        "            for n in 1:size(struct_element)[2]\n",
        "                ni = i + m - offset_h - 1\n",
        "                nj = j + n - offset_w - 1\n",
        "\n",
        "                # Only check input if it's in bounds\n",
        "                if 1 <= ni <= size(input_img)[1] && 1 <= nj <= size(input_img)[2]\n",
        "                    if input_img[ni, nj] == 1 && struct_element[m, n] == 1\n",
        "                        result = true\n",
        "                        break\n",
        "                    end\n",
        "                end\n",
        "\n",
        "            end\n",
        "            if result\n",
        "                break\n",
        "            end\n",
        "        end\n",
        "\n",
        "        @inbounds output_img[i, j] = result ? 1 : 0\n",
        "    end\n",
        "end\n",
        "\n",
        "\n",
        "function dilate_2D!(output, img_input, struct_element)\n",
        "\n",
        "    backend = get_backend(img_input)\n",
        "    kernel! = dilate_kernel!(backend)\n",
        "    kernel!(output, img_input, struct_element, ndrange = size(output))\n",
        "\n",
        "    return output\n",
        "end\n",
        "\n"
      ],
      "metadata": {
        "id": "czwFEcIa0Yuw",
        "outputId": "c2d37bd9-85dd-4d6c-e1ba-e09fbdcb9f10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dilate_2D! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------erosion---------------------------------------\n",
        "\n",
        "@kernel function erode_kernel!(output_img, input_img, struct_element)\n",
        "    I = @index(Global, Cartesian)\n",
        "    i, j = Tuple(I)\n",
        "    offset_h = div(size(struct_element)[1], 2)\n",
        "    offset_w = div(size(struct_element)[2], 2)\n",
        "\n",
        "    if i <= size(input_img, 1) && j <= size(input_img, 2)\n",
        "        result = true\n",
        "\n",
        "        for m in 1:size(struct_element)[1]\n",
        "            for n in 1:size(struct_element)[2]\n",
        "                ni = i + m - offset_h - 1\n",
        "                nj = j + n - offset_w - 1\n",
        "\n",
        "                if 1 <= ni <= size(input_img)[1] && 1 <= nj <= size(input_img)[2]\n",
        "                    if struct_element[m, n] == 1 && input_img[ni, nj] == 0\n",
        "                        result = false\n",
        "                        break\n",
        "                    end\n",
        "                else\n",
        "                    # Out-of-bounds counts as 0 in erosion\n",
        "                    if struct_element[m, n] == 1\n",
        "                        result = false\n",
        "                        break\n",
        "                    end\n",
        "                end\n",
        "            end\n",
        "            if !result\n",
        "                break\n",
        "            end\n",
        "        end\n",
        "\n",
        "        @inbounds output_img[i, j] = result ? 1 : 0\n",
        "    end\n",
        "end\n",
        "\n",
        "\n",
        "function erode_2D!(output, img_input, struct_element)\n",
        "\n",
        "    backend = get_backend(img_input)\n",
        "    kernel! = erode_kernel!(backend)\n",
        "    kernel!(output, img_input, struct_element, ndrange = size(output))\n",
        "\n",
        "    return output\n",
        "end\n"
      ],
      "metadata": {
        "id": "y6yk376d3hb7",
        "outputId": "b7ebec24-bd9e-4335-b419-f13e46a44c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "erode_2D! (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function testing()\n",
        "    # === Input for dilation (CPU & GPU)\n",
        "    img_input_dilation = Bool[\n",
        "        0 0 0 0 0 0 0 0 0 0 0;\n",
        "        0 1 1 1 1 0 0 1 1 1 0;\n",
        "        0 1 1 1 1 0 0 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 0 0 0 1 1 1 1 0;\n",
        "        0 1 1 0 0 0 1 1 1 1 0;\n",
        "        0 1 1 0 0 0 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 0 0 0;\n",
        "        0 1 1 1 1 1 1 1 0 0 0;\n",
        "        0 0 0 0 0 0 0 0 0 0 0;\n",
        "    ]\n",
        "\n",
        "    expected_result_dilation = Bool[\n",
        "        1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 0 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 0 0;\n",
        "        1 1 1 1 1 1 1 1 1 0 0;\n",
        "    ]\n",
        "\n",
        "    # === Input for erosion (CPU & GPU)\n",
        "    img_input_erosion = Bool[\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 0 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "        1 1 1 1 1 1 1 1 1 1 1 1 1;\n",
        "    ]\n",
        "\n",
        "    expected_result_erosion = Bool[\n",
        "        0 0 0 0 0 0 0 0 0 0 0 0 0;\n",
        "        0 1 1 1 1 0 0 0 1 1 1 1 0;\n",
        "        0 1 1 1 1 0 0 0 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 1 1 1 1 1 1 1 1 1 1 1 0;\n",
        "        0 0 0 0 0 0 0 0 0 0 0 0 0;\n",
        "    ]\n",
        "\n",
        "    # Structuring element\n",
        "    struct_element = ones(Bool, 3, 3)\n",
        "\n",
        "    # Output arrays (CPU)\n",
        "    output_dilation = zeros(Bool, size(expected_result_dilation))\n",
        "    output_erosion = zeros(Bool, size(expected_result_erosion))\n",
        "\n",
        "    # Call CPU versions\n",
        "    dilate_2D!(output_dilation, img_input_dilation, struct_element)\n",
        "    erode_2D!(output_erosion, img_input_erosion, struct_element)\n",
        "\n",
        "    @test output_dilation == expected_result_dilation\n",
        "    @test output_erosion == expected_result_erosion\n",
        "\n",
        "    # GPU versions\n",
        "    d_img_input_dilation = CuArray(img_input_dilation)\n",
        "    d_img_input_erosion = CuArray(img_input_erosion)\n",
        "    d_struct_element = CuArray(struct_element)\n",
        "\n",
        "    d_output_dilation = CuArray(zeros(Bool, size(expected_result_dilation)))\n",
        "    d_output_erosion = CuArray(zeros(Bool, size(expected_result_erosion)))\n",
        "\n",
        "    dilate_2D!(d_output_dilation, d_img_input_dilation, d_struct_element)\n",
        "    erode_2D!(d_output_erosion, d_img_input_erosion, d_struct_element)\n",
        "\n",
        "    # Bring results back from GPU\n",
        "    gpu_result_dilation = Array(d_output_dilation)\n",
        "    gpu_result_erosion = Array(d_output_erosion)\n",
        "\n",
        "    @test gpu_result_dilation == expected_result_dilation\n",
        "    @test gpu_result_erosion == expected_result_erosion\n",
        "end"
      ],
      "metadata": {
        "id": "mqGK2g0w9dqr",
        "outputId": "d131f838-d045-48b1-f6b5-78fa934f3ade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "testing (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing()"
      ],
      "metadata": {
        "id": "8EzPtBac1TnR",
        "outputId": "0ed5ca03-81b4-417c-9727-6e256ff790b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}